{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bde031",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ¤– A Guide to the Different Types of AI Agents\n",
    "\n",
    "AI agents can be categorized based on their intelligence and capabilities. They range from simple, reactive systems to complex, learning-based agents. Hereâ€™s a breakdown of the primary types, from the simplest to the most advanced.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. âž¡ï¸ Simple Reflex Agents\n",
    "\n",
    "These are the most basic type of agents. They make decisions based only on the **current percept** (what they sense right now), ignoring the rest of the percept history.\n",
    "\n",
    "-   **How they work:** They use simple **Condition-Action rules** (if-then statements).\n",
    "-   **Example:** A thermostat that turns on the AC if the temperature is above 74Â°F. It doesn't care what the temperature was an hour ago; it only reacts to the current reading.\n",
    "-   **Limitation:** They have very limited intelligence and cannot operate in environments where the correct decision requires knowledge of past states.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. ðŸ§  Model-Based Reflex Agents\n",
    "\n",
    "These agents build upon simple reflex agents by maintaining an **internal state** or \"model\" of the world. This model helps them understand how the world changes and how their own actions affect it.\n",
    "\n",
    "-   **How they work:** They store a representation of the parts of the world they can't see right now. This allows them to handle partially observable environments.\n",
    "-   **Example:** An autonomous car that needs to change lanes. It can't see every other car at once, but its internal model tracks the likely positions of other cars based on their past speeds and trajectories.\n",
    "-   **Limitation:** They know *how* the world works, but they don't have a specific **goal** to achieve.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ðŸŽ¯ Goal-Based Agents\n",
    "\n",
    "Goal-based agents take the next step by having an explicit **goal** to achieve. They use their model of the world to choose actions that will lead them closer to their goal state.\n",
    "\n",
    "-   **How they work:** They combine their internal model with a goal. This makes their decision-making more flexible. Instead of being hard-coded to do one thing, they can choose from multiple actions to find one that achieves the goal.\n",
    "-   **Example:** A package delivery robot. Its goal is to deliver a package to a specific location. It can choose different paths to get there, and if one path is blocked, it can find an alternative route to still reach its goal.\n",
    "-   **Limitation:** They treat all goals as equal. They don't have a way to decide if one successful outcome is \"better\" than another.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. âœ¨ Utility-Based Agents\n",
    "\n",
    "Utility-based agents are a more advanced form of goal-based agents. They don't just have a goal; they also have a **utility function** that measures the \"happiness\" or desirability of a particular state. This allows them to make trade-offs between conflicting goals.\n",
    "\n",
    "-   **How they work:** They choose the action that leads to the state with the **highest expected utility**. This is useful when there are multiple possible outcomes, some of which are better than others.\n",
    "-   **Example:** A ride-sharing app's dispatch agent. Its goal is to assign a car to a rider. But it has multiple objectives: minimize wait time, minimize cost, and maximize driver satisfaction. A utility function helps it weigh these factors to find the best possible assignment.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. ðŸŽ“ Learning Agents\n",
    "\n",
    "Learning agents are the most advanced type. They can operate in unknown environments and become more competent over time. They have a \"learning element\" that allows them to improve their performance through experience.\n",
    "\n",
    "-   **How they work:** They start with some basic knowledge and then learn from their actions. A \"critic\" component provides feedback on how well the agent is doing, and the learning element uses this feedback to modify the agent's decision-making rules.\n",
    "-   **Example:** A master chess-playing AI. It doesn't just play based on pre-programmed rules. It plays millions of games against itself (a form of **Reinforcement Learning**), learns which moves lead to wins, and continuously improves its strategy.\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Hierarchy\n",
    "\n",
    "You can think of these agents as building on top of each other:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Simple Reflex Agent] --> B[Model-Based Agent];\n",
    "    B --> C[Goal-Based Agent];\n",
    "    C --> D[Utility-Based Agent];\n",
    "    subgraph Most Advanced\n",
    "        E[Learning Agent]\n",
    "    end\n",
    "    D --> E;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
