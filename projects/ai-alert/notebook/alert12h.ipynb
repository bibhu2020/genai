{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8a8694",
   "metadata": {},
   "source": [
    "### KPI - Availability (Sev4: Burn Velocity > 1x in 12 hrs windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4cdc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install azure-identity azure-monitor-query langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee096918",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the credential to query log analytics\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.monitor.query import LogsQueryClient, LogsQueryStatus\n",
    "import pandas as pd\n",
    "\n",
    "# Azure config\n",
    "tenant_id = \"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "# workspace_id = \"edf08e1f-916f-48c3-bc52-273492d63c8f\" #data connector\n",
    "# workspace_id = \"edf08e1f-916f-48c3-bc52-273492d63c8f\" #msonecloud tool\n",
    "workspace_id = \"5938c293-3317-4e63-9b33-a248eb20cc81\" #blogging sites\n",
    "\n",
    "# Auth\n",
    "credential = DefaultAzureCredential()\n",
    "client = LogsQueryClient(credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TimeGenerated, totalRequests, errorRequests, SLI, burnRate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Burn Rate for slo = 99.95% in 5 minutes window\n",
    "# Fire this alert in every 5 minutes\n",
    "\n",
    "#   and Resource == \"MSONECLOUDAPIFD\"\n",
    "\n",
    "\n",
    "slo = 0.9995\n",
    "timeGrain = \"12h\"\n",
    "\n",
    "query = f\"\"\"\n",
    "\n",
    "let SLO = {slo};\n",
    "let timeGrain = {timeGrain};\n",
    "AzureDiagnostics\n",
    "| where TimeGenerated > ago(30d)\n",
    "  and Category == \"FrontDoorAccessLog\"\n",
    "| where isnotempty(httpStatusCode_s)\n",
    "| extend statusCode = toint(httpStatusCode_s)\n",
    "| summarize\n",
    "    totalRequests = count(),\n",
    "    errorRequests = countif(statusCode >= 500)\n",
    "    by bin(TimeGenerated, timeGrain)\n",
    "| extend SLI = iff(totalRequests > 0, 1.0 - (1.0 * errorRequests / totalRequests), 1.0)\n",
    "| extend burnRate = iff(totalRequests > 0, (1.0 - SLI) / (1.0 - SLO), 0.0)\n",
    "| project TimeGenerated, totalRequests, errorRequests, SLI, burnRate\n",
    "| order by TimeGenerated asc\n",
    "\"\"\"\n",
    "\n",
    "# Query execution\n",
    "response = client.query_workspace(\n",
    "    workspace_id=workspace_id,\n",
    "    query=query,\n",
    "    timespan=None\n",
    ")\n",
    "\n",
    "# Parse results\n",
    "if response.status == LogsQueryStatus.SUCCESS:\n",
    "    table = response.tables[0]\n",
    "    df = pd.DataFrame(data=table.rows, columns=table.columns)\n",
    "    df[\"TimeGenerated\"] = pd.to_datetime(df[\"TimeGenerated\"])\n",
    "    df = df.sort_values(\"TimeGenerated\")\n",
    "\n",
    "print(max_burnrate_df.head(10))\n",
    "\n",
    "max_burnrate_df = df[(df[\"burnRate\"] == df[\"burnRate\"].max()) & (df[\"burnRate\"].max() >= 1) ]\n",
    "# max_burnrate_df = df[(df[\"burnRate\"] == df[\"burnRate\"].max()) ]\n",
    "\n",
    "# print(df[\"burnRate\"].max())\n",
    "# print(max_burnrate_df.sample(10))\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    max_burn_row = max_burnrate_df.iloc[0]\n",
    "    print(max_burn_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       TimeGenerated       type      OperationName  \\\n",
      "138 2025-05-14 23:55:00.545870+00:00    request  GET Product/Price   \n",
      "658 2025-05-14 23:55:00.560288+00:00  exception  GET Product/Price   \n",
      "139 2025-05-14 23:55:00.874952+00:00    request  GET Product/Price   \n",
      "659 2025-05-14 23:55:00.887148+00:00  exception  GET Product/Price   \n",
      "140 2025-05-14 23:55:06.402061+00:00    request  GET Product/Price   \n",
      "..                               ...        ...                ...   \n",
      "638 2025-05-15 00:04:57.126307+00:00  exception  GET Product/Price   \n",
      "136 2025-05-15 00:04:57.863500+00:00    request  GET Product/Price   \n",
      "639 2025-05-15 00:04:57.877303+00:00  exception  GET Product/Price   \n",
      "137 2025-05-15 00:04:58.665034+00:00    request  GET Product/Price   \n",
      "640 2025-05-15 00:04:58.677220+00:00  exception  GET Product/Price   \n",
      "\n",
      "                  Name ResultCode  DurationMs Success  \\\n",
      "138  GET Product/Price        500     14.8581   False   \n",
      "658                NaN        NaN         NaN     NaN   \n",
      "139  GET Product/Price        500     12.6048   False   \n",
      "659                NaN        NaN         NaN     NaN   \n",
      "140  GET Product/Price        500     12.2453   False   \n",
      "..                 ...        ...         ...     ...   \n",
      "638                NaN        NaN         NaN     NaN   \n",
      "136  GET Product/Price        500     14.2675   False   \n",
      "639                NaN        NaN         NaN     NaN   \n",
      "137  GET Product/Price        500     12.6557   False   \n",
      "640                NaN        NaN         NaN     NaN   \n",
      "\n",
      "                                             ProblemId OuterMessage Target  \n",
      "138                                                NaN          NaN    NaN  \n",
      "658  System.IO.FileNotFoundException at OneCloud.Da...                 NaN  \n",
      "139                                                NaN          NaN    NaN  \n",
      "659  System.IO.FileNotFoundException at OneCloud.Da...                 NaN  \n",
      "140                                                NaN          NaN    NaN  \n",
      "..                                                 ...          ...    ...  \n",
      "638  System.IO.FileNotFoundException at OneCloud.Da...                 NaN  \n",
      "136                                                NaN          NaN    NaN  \n",
      "639  System.IO.FileNotFoundException at OneCloud.Da...                 NaN  \n",
      "137                                                NaN          NaN    NaN  \n",
      "640  System.IO.FileNotFoundException at OneCloud.Da...                 NaN  \n",
      "\n",
      "[932 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from pandas import Timedelta\n",
    "from azure.monitor.query import LogsQueryStatus\n",
    "\n",
    "def merge_with_role_and_time(base_df, other_df, tolerance=\"2s\"):\n",
    "    if base_df.empty or other_df.empty:\n",
    "        return base_df\n",
    "\n",
    "    # Ensure datetime format and sorting\n",
    "    base_df[\"TimeGenerated\"] = pd.to_datetime(base_df[\"TimeGenerated\"])\n",
    "    other_df[\"TimeGenerated\"] = pd.to_datetime(other_df[\"TimeGenerated\"])\n",
    "\n",
    "    base_df.sort_values([\"AppRoleName\", \"TimeGenerated\"], inplace=True)\n",
    "    other_df.sort_values([\"AppRoleName\", \"TimeGenerated\"], inplace=True)\n",
    "\n",
    "    merged_chunks = []\n",
    "\n",
    "    for role, base_group in base_df.groupby(\"AppRoleName\"):\n",
    "        other_group = other_df[other_df[\"AppRoleName\"] == role]\n",
    "\n",
    "        if other_group.empty:\n",
    "            merged_chunks.append(base_group)\n",
    "            continue\n",
    "\n",
    "        # Drop overlapping columns except merge keys to allow overwrite\n",
    "        overlapping = set(base_group.columns) & set(other_group.columns) - {\"TimeGenerated\", \"AppRoleName\"}\n",
    "        other_group = other_group.drop(columns=overlapping)\n",
    "\n",
    "        merged = pd.merge_asof(\n",
    "            base_group,\n",
    "            other_group,\n",
    "            on=\"TimeGenerated\",\n",
    "            by=\"AppRoleName\",\n",
    "            direction=\"nearest\",\n",
    "            tolerance=Timedelta(tolerance)\n",
    "        )\n",
    "\n",
    "        merged_chunks.append(merged)\n",
    "\n",
    "    return pd.concat(merged_chunks).sort_values(\"TimeGenerated\")\n",
    "\n",
    "\n",
    "# ========== LOGIC ==========\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "\n",
    "    spike_time = max_burn_row['TimeGenerated']\n",
    "    start_time = spike_time - timedelta(minutes=5)\n",
    "    end_time = spike_time + timedelta(minutes=5)\n",
    "    timespan = (start_time, end_time)\n",
    "\n",
    "    tables = {\n",
    "        \"AppRequests\": f\"\"\"\n",
    "            AppRequests\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and Success == false\n",
    "            and toint(ResultCode) >= 500\n",
    "            | project TimeGenerated, type=\"request\", OperationName, Name, ResultCode, Duration = DurationMs, Success, AppRoleName\n",
    "        \"\"\",\n",
    "        \"AppExceptions\": f\"\"\"\n",
    "            AppExceptions\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and ProblemId != \"Microsoft.IdentityModel.S2S.S2SAuthenticationException\"\n",
    "            | project TimeGenerated, type=\"exception\", OperationName, ProblemId, Message = OuterMessage, AppRoleName\n",
    "        \"\"\",\n",
    "        \"AppTraces\": f\"\"\"\n",
    "            AppTraces\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and SeverityLevel >= 2\n",
    "            | project TimeGenerated, type=\"trace\", Message, SeverityLevel, AppRoleName\n",
    "        \"\"\",\n",
    "        \"AppDependencies\": f\"\"\"\n",
    "            AppDependencies\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and Success == false\n",
    "            | project TimeGenerated, type=\"dependency\", Name, Target = Data, ResultCode, Success, Duration = DurationMs, AppRoleName, Server = AppRoleName\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # Query logs\n",
    "    log_dict = {}\n",
    "    for table_name, query in tables.items():\n",
    "        resp = client.query_workspace(workspace_id, query, timespan=timespan)\n",
    "        if resp.status == LogsQueryStatus.SUCCESS:\n",
    "            tab = resp.tables[0]\n",
    "            df = pd.DataFrame(tab.rows, columns=tab.columns)\n",
    "            df[\"type\"] = table_name  # optional, override type for traceability\n",
    "            log_dict[table_name] = df\n",
    "\n",
    "    # Merge logs with preference starting from AppRequests\n",
    "    merged_logs = log_dict.get(\"AppRequests\", pd.DataFrame())\n",
    "\n",
    "    for table_name in [\"AppExceptions\", \"AppTraces\", \"AppDependencies\"]:\n",
    "        other_df = log_dict.get(table_name, pd.DataFrame())\n",
    "        merged_logs = merge_with_role_and_time(merged_logs, other_df, tolerance=\"2s\")\n",
    "\n",
    "    # Final formatting\n",
    "    merged_logs.sort_values(\"TimeGenerated\", inplace=True)\n",
    "    merged_logs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Output: merged_logs is your final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3b8b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(timespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b64042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format for LLM\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    lines = []\n",
    "    for _, row in merged_logs.iterrows():\n",
    "        summary = f\"[{row['TimeGenerated']}] [{row['type']}] \" + \" | \".join(f\"{k}={row[k]}\" for k in row.index if k not in ['TimeGenerated', 'type'])\n",
    "        lines.append(summary)\n",
    "\n",
    "    log_context = \"\\n\".join(lines[:30])  # Trim for LLM input\n",
    "\n",
    "    log_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dbac2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to LLM\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    prompt_text = f\"\"\"\n",
    "    A spike in error burn rate was detected between {start_time} and {end_time}.\n",
    "\n",
    "    Here are logs across request, exception, trace, and dependency tables:\n",
    "\n",
    "    {log_context}\n",
    "\n",
    "    Analyze the root cause and recommend how to mitigate or fix the issue.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75119ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4541cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Incident Analysis by LLM ===\n",
      "\n",
      "Analyzing the logs provided, all the exceptions thrown during the said period are of type 'System.IO.FileNotFoundException' originating from 'OneCloud.DataConnector.M365.Controllers.ProductController.CreateProductRequestFrom'. This indicates that there is an issue accessing a file needed to retrieve the product price.\n",
      "\n",
      "This issue might be caused by one of the following reasons:\n",
      "\n",
      "1. The file doesn't exist: The system is trying to access a file that doesn't exist at the location specified in the code.\n",
      "2. Incorrect file path: The file path specified in the code could be wrong.\n",
      "3. Lack of permissions: The service might not have the appropriate permissions to read the file.\n",
      "\n",
      "Here's how to mitigate or fix the issue:\n",
      "\n",
      "1. Check the file's existence: Verify if that the file which the system is trying to access actually exists at the location specified in the code.\n",
      "\n",
      "2. Correct file path: Ensure that the correct file path is provided in 'ProductController.CreateProductRequestFrom'. Confirm that the file name and extension are correct too.\n",
      "\n",
      "3. Set appropriate permissions: If the system lacks the necessary permissions to access the file, granting the appropriate permissions to the service will resolve the issue.\n",
      "\n",
      "4. Improve Error Logging: Exception statements could provide more details including paths and identifiers being accessed aiding in faster root cause identification.\n",
      "\n",
      "5. Defensive programming: Implement file existence checks prior to reading files, reducing the risk of such exceptions.\n",
      "\n",
      "After implementing these points, make sure to test your service thoroughly to ensure everything is working correctly.\n"
     ]
    }
   ],
   "source": [
    "# Connect to LLM using my libraries\n",
    "from utility.llm_factory import LLMFactory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                You are a skilled and detail-oriented Site Reliability Engineering (SRE) assistant.\n",
    "                Your primary goal is to help identify the root cause of incidents based on system logs and telemetry.\n",
    "\n",
    "                - Summerize the issue in 1 bullet point only.\n",
    "                - Focus on pinpointing the **source of the error**, **server name** and the **exact or approximate time** it occurred.\n",
    "                - Keep the **root-cause** elaborated in 2-3 bullet points max.\n",
    "                - If applicable, correlate related events across logs.\n",
    "                - Keep your **mitigation and next steps** clear and concise (2-3 bullet points max).\n",
    "                - Avoid vague conclusions. Use specific log details to support your reasoning.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{prompt_text}\")\n",
    "        ])\n",
    "\n",
    "    # print(prompt)\n",
    "\n",
    "    llm = LLMFactory.get_llm('openai')\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    result = chain.invoke({\"prompt_text\": prompt_text })\n",
    "\n",
    "    print(\"=== Incident Analysis by LLM ===\\n\")\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
