{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8a8694",
   "metadata": {},
   "source": [
    "### KPI - Availability (Sev2: Burn Velocity > 6x in 30 mins windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cdc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install azure-identity azure-monitor-query langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee096918",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the credential to query log analytics\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.monitor.query import LogsQueryClient, LogsQueryStatus\n",
    "import pandas as pd\n",
    "\n",
    "# Azure config\n",
    "tenant_id = \"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "workspace_id = \"edf08e1f-916f-48c3-bc52-273492d63c8f\"\n",
    "\n",
    "# Auth\n",
    "credential = DefaultAzureCredential()\n",
    "client = LogsQueryClient(credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a1a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Burn Rate for slo = 99.95% in 5 minutes window\n",
    "# Fire this alert in every 5 minutes\n",
    "\n",
    "slo = 0.9995\n",
    "timeGrain = \"30m\"\n",
    "\n",
    "query = f\"\"\"\n",
    "\n",
    "let SLO = {slo};\n",
    "let timeGrain = {timeGrain};\n",
    "AzureDiagnostics\n",
    "| where TimeGenerated > ago(24h)\n",
    "  and Resource == \"MSONECLOUDAPIFD\"\n",
    "  and Category == \"FrontDoorAccessLog\"\n",
    "| where isnotempty(httpStatusCode_s)\n",
    "| extend statusCode = toint(httpStatusCode_s)\n",
    "| summarize\n",
    "    totalRequests = count(),\n",
    "    errorRequests = countif(statusCode >= 500)\n",
    "    by bin(TimeGenerated, timeGrain)\n",
    "| extend SLI = iff(totalRequests > 0, 1.0 - (1.0 * errorRequests / totalRequests), 1.0)\n",
    "| extend burnRate = iff(totalRequests > 0, (1.0 - SLI) / (1.0 - SLO), 0.0)\n",
    "| project TimeGenerated, totalRequests, errorRequests, SLI, burnRate\n",
    "| order by TimeGenerated asc\n",
    "\"\"\"\n",
    "\n",
    "# Query execution\n",
    "response = client.query_workspace(\n",
    "    workspace_id=workspace_id,\n",
    "    query=query,\n",
    "    timespan=None\n",
    ")\n",
    "\n",
    "# Parse results\n",
    "if response.status == LogsQueryStatus.SUCCESS:\n",
    "    table = response.tables[0]\n",
    "    df = pd.DataFrame(data=table.rows, columns=table.columns)\n",
    "    df[\"TimeGenerated\"] = pd.to_datetime(df[\"TimeGenerated\"])\n",
    "    df = df.sort_values(\"TimeGenerated\")\n",
    "\n",
    "max_burnrate_df = df[(df[\"burnRate\"] == df[\"burnRate\"].max()) & (df[\"burnRate\"].max() >= 6) ]\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    max_burn_row = max_burnrate_df.iloc[0]\n",
    "    print(max_burn_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c709630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from pandas import Timedelta\n",
    "from azure.monitor.query import LogsQueryStatus\n",
    "\n",
    "def merge_with_role_and_time(base_df, other_df, tolerance=\"2s\"):\n",
    "    if base_df.empty or other_df.empty:\n",
    "        return base_df\n",
    "\n",
    "    # Ensure datetime format and sorting\n",
    "    base_df[\"TimeGenerated\"] = pd.to_datetime(base_df[\"TimeGenerated\"])\n",
    "    other_df[\"TimeGenerated\"] = pd.to_datetime(other_df[\"TimeGenerated\"])\n",
    "\n",
    "    base_df.sort_values([\"AppRoleName\", \"TimeGenerated\"], inplace=True)\n",
    "    other_df.sort_values([\"AppRoleName\", \"TimeGenerated\"], inplace=True)\n",
    "\n",
    "    merged_chunks = []\n",
    "\n",
    "    for role, base_group in base_df.groupby(\"AppRoleName\"):\n",
    "        other_group = other_df[other_df[\"AppRoleName\"] == role]\n",
    "\n",
    "        if other_group.empty:\n",
    "            merged_chunks.append(base_group)\n",
    "            continue\n",
    "\n",
    "        # Drop overlapping columns except merge keys to allow overwrite\n",
    "        overlapping = set(base_group.columns) & set(other_group.columns) - {\"TimeGenerated\", \"AppRoleName\"}\n",
    "        other_group = other_group.drop(columns=overlapping)\n",
    "\n",
    "        merged = pd.merge_asof(\n",
    "            base_group,\n",
    "            other_group,\n",
    "            on=\"TimeGenerated\",\n",
    "            by=\"AppRoleName\",\n",
    "            direction=\"nearest\",\n",
    "            tolerance=Timedelta(tolerance)\n",
    "        )\n",
    "\n",
    "        merged_chunks.append(merged)\n",
    "\n",
    "    return pd.concat(merged_chunks).sort_values(\"TimeGenerated\")\n",
    "\n",
    "\n",
    "# ========== LOGIC ==========\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "\n",
    "    spike_time = max_burn_row['TimeGenerated']\n",
    "    start_time = spike_time - timedelta(minutes=5)\n",
    "    end_time = spike_time + timedelta(minutes=5)\n",
    "    timespan = (start_time, end_time)\n",
    "\n",
    "    tables = {\n",
    "        \"AppRequests\": f\"\"\"\n",
    "            AppRequests\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and Success == false\n",
    "            and toint(ResultCode) >= 500\n",
    "            | project TimeGenerated, type=\"request\", OperationName, Name, ResultCode, Duration = DurationMs, Success, AppRoleName\n",
    "        \"\"\",\n",
    "        \"AppExceptions\": f\"\"\"\n",
    "            AppExceptions\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and ProblemId != \"Microsoft.IdentityModel.S2S.S2SAuthenticationException\"\n",
    "            | project TimeGenerated, type=\"exception\", OperationName, ProblemId, Message = OuterMessage, AppRoleName\n",
    "        \"\"\",\n",
    "        \"AppTraces\": f\"\"\"\n",
    "            AppTraces\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and SeverityLevel >= 2\n",
    "            | project TimeGenerated, type=\"trace\", Message, SeverityLevel, AppRoleName\n",
    "        \"\"\",\n",
    "        \"AppDependencies\": f\"\"\"\n",
    "            AppDependencies\n",
    "            | where TimeGenerated between (datetime({start_time.isoformat()}) .. datetime({end_time.isoformat()}))\n",
    "            and AppRoleName contains \"msonecloudapi-prod\"\n",
    "            and Success == false\n",
    "            | project TimeGenerated, type=\"dependency\", Name, Target = Data, ResultCode, Success, Duration = DurationMs, AppRoleName, Server = AppRoleName\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # Query logs\n",
    "    log_dict = {}\n",
    "    for table_name, query in tables.items():\n",
    "        resp = client.query_workspace(workspace_id, query, timespan=timespan)\n",
    "        if resp.status == LogsQueryStatus.SUCCESS:\n",
    "            tab = resp.tables[0]\n",
    "            df = pd.DataFrame(tab.rows, columns=tab.columns)\n",
    "            df[\"type\"] = table_name  # optional, override type for traceability\n",
    "            log_dict[table_name] = df\n",
    "\n",
    "    # Merge logs with preference starting from AppRequests\n",
    "    merged_logs = log_dict.get(\"AppRequests\", pd.DataFrame())\n",
    "\n",
    "    for table_name in [\"AppExceptions\", \"AppTraces\", \"AppDependencies\"]:\n",
    "        other_df = log_dict.get(table_name, pd.DataFrame())\n",
    "        merged_logs = merge_with_role_and_time(merged_logs, other_df, tolerance=\"2s\")\n",
    "\n",
    "    # Final formatting\n",
    "    merged_logs.sort_values(\"TimeGenerated\", inplace=True)\n",
    "    merged_logs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Output: merged_logs is your final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b8b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(timespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b64042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format for LLM\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    lines = []\n",
    "    for _, row in merged_logs.iterrows():\n",
    "        summary = f\"[{row['TimeGenerated']}] [{row['type']}] \" + \" | \".join(f\"{k}={row[k]}\" for k in row.index if k not in ['TimeGenerated', 'type'])\n",
    "        lines.append(summary)\n",
    "\n",
    "    log_context = \"\\n\".join(lines[:30])  # Trim for LLM input\n",
    "\n",
    "    log_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dbac2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to LLM\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    prompt_text = f\"\"\"\n",
    "    A spike in error burn rate was detected between {start_time} and {end_time}.\n",
    "\n",
    "    Here are logs across request, exception, trace, and dependency tables:\n",
    "\n",
    "    {log_context}\n",
    "\n",
    "    Analyze the root cause and recommend how to mitigate or fix the issue.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75119ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4541cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Connect to LLM using my libraries\n",
    "from utility.llm_factory import LLMFactory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "if max_burnrate_df.shape[0] > 0:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                You are a skilled and detail-oriented Site Reliability Engineering (SRE) assistant.\n",
    "                Your primary goal is to help identify the root cause of incidents based on system logs and telemetry.\n",
    "\n",
    "                - Summerize the issue in 1 bullet point only.\n",
    "                - Focus on pinpointing the **source of the error**, **server name** and the **exact or approximate time** it occurred.\n",
    "                - Keep the **root-cause** elaborated in 2-3 bullet points max.\n",
    "                - If applicable, correlate related events across logs.\n",
    "                - Keep your **mitigation and next steps** clear and concise (2-3 bullet points max).\n",
    "                - Avoid vague conclusions. Use specific log details to support your reasoning.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{prompt_text}\")\n",
    "        ])\n",
    "\n",
    "    # print(prompt)\n",
    "\n",
    "    llm = LLMFactory.get_llm('openai')\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    result = chain.invoke({\"prompt_text\": prompt_text })\n",
    "\n",
    "    print(\"=== Incident Analysis by LLM ===\\n\")\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
