{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4986c4eb",
   "metadata": {},
   "source": [
    "## Demo - Search Engine with Tools and Agents\n",
    "**Use Case**\n",
    "\n",
    "The limitation with LLM models is that they are trained with past data until a period. If there is need of latest information, you integrate LLM with tools that connects to external world.\n",
    "\n",
    "Here in this usecase, we are going to build an application that connects with 3 tools:\n",
    "\n",
    "1. ARXIV (built-in tool) that pulls data from ARXIV website that stores the research papers.\n",
    "\n",
    "2. WikiPedia (built-in tool) that pulls information from wikipedia website.\n",
    "\n",
    "3. RAG (a custom-tool) that pulls the data from a RAG vectorstore that stores web-scrapped contents from \"https://docs.smith.langchain.com/\"\n",
    "\n",
    "We would demonstrate the agent connecting to the right tool based on user input to fetch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step1: Initialize the LLM Model\n",
    "from utility.llm_factory import LLMFactory\n",
    "llm = LLMFactory.get_llm('openai')\n",
    "\n",
    "from utility.embedding_factory import EmbeddingFactory\n",
    "\n",
    "embedding_model = EmbeddingFactory.get_llm('openai')\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step2: Import the packages\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step3: Arxiv -- Research\n",
    "### A tool (inbuilt tool) that allows you to search and download papers from arxiv.org\n",
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1, doc_dcontent_chars_max=250)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "\n",
    "arxiv_tool.name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step4: Wikipedia\n",
    "### A tool (inbuilt tool) that allows you to search and download articles from Wikipedia\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1, doc_dcontent_chars_max=250)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "\n",
    "wiki_tool.name \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b62742",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step5: A custom RAG tool that queries a website and returns the content\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# âœ… Use 'parse_only' instead of 'parser_only'\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://docs.smith.langchain.com/\",)\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Note: the input here is a list of Document objects, not just strings.\n",
    "document_chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "document_chunks[::] \n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "vector_store_db = Chroma.from_documents(\n",
    "    document_chunks,\n",
    "    embedding_model,\n",
    "    collection_name=\"tooltest_collection\",\n",
    "    persist_directory=\"./_data/chroma_db\"\n",
    ")\n",
    "# Check the number of documents in the vector store\n",
    "print(f\"Number of documents in the vector store: {vector_store_db._collection.count()}\")\n",
    "\n",
    "retriever = vector_store_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "from langchain_community.tools import Tool\n",
    "rag_tool = Tool(\n",
    "    name=\"rag_tool\",\n",
    "    func=retriever.invoke,\n",
    "    description=\"Search any information about langsmith.\"\n",
    ")   \n",
    "rag_tool.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c081fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step6: Create a list of tools\n",
    "tools = [arxiv_tool, wiki_tool, rag_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc880d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7280c8dcc990>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7280b01b1390>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=512)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step7: Initialize the LLM that the Agent would use to decide which tool to use\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_groq = ChatGroq(model=\"Gemma2-9b-It\", max_tokens=512)\n",
    "llm_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a3da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step8: Initialize the Agent with the tools and LLM\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_groq,\n",
    "    agent=\"zero-shot-react-description\",  # Let the LLM reason and act\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.invoke(\"Who is aurangzeb? What is his contribution to the Mughal Empire?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7be950fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the latest research on quantum computing, I should use arxiv. \n",
      "Action: arxiv\n",
      "Action Input: quantum computing\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2022-08-01\n",
      "Title: The Rise of Quantum Internet Computing\n",
      "Authors: Seng W. Loke\n",
      "Summary: This article highlights quantum Internet computing as referring to\n",
      "distributed quantum computing over the quantum Internet, analogous to\n",
      "(classical) Internet computing involving (classical) distributed computing over\n",
      "the (classical) Internet. Relevant to quantum Internet computing would be areas\n",
      "of study such as quantum protocols for distributed nodes using quantum\n",
      "information for computations, quantum cloud computing, delegated verifiable\n",
      "blind or private computing, non-local gates, and distributed quantum\n",
      "applications, over Internet-scale distances.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: This looks like a good starting point. I could explore other recent papers on arxiv to get a broader view.  \n",
      "Action: arxiv\n",
      "Action Input: quantum computing + recent\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2003-05-05\n",
      "Title: Quantum computer: an appliance for playing market games\n",
      "Authors: Edward W. Piotrowski, Jan Sladkowski\n",
      "Summary: Recent development in quantum computation and quantum information theory\n",
      "allows to extend the scope of game theory for the quantum world. The authors\n",
      "have recently proposed a quantum description of financial market in terms of\n",
      "quantum game theory. The paper contain an analysis of such markets that shows\n",
      "that there would be advantage in using quantum computers and quantum\n",
      "strategies.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I see that arxiv is providing papers from 2022 and 2003.  It seems like I need to refine my search to focus on very recent papers.  \n",
      "\n",
      "Action: arxiv\n",
      "Action Input: quantum computing + recent + 2023\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2023-08-03\n",
      "Title: Q-Map: Quantum Circuit Implementation of Boolean Functions\n",
      "Authors: Hassan Hajjdiab, Ashraf Khalil, Hichem Eleuch\n",
      "Summary: Quantum computing has gained attention in recent years due to the significant\n",
      "progress in quantum computing technology. Today many companies like IBM, Google\n",
      "and Microsoft have developed quantum computers and simulators for research and\n",
      "commercial use. The development of quantum techniques and algorithms is\n",
      "essential to exploit the full power of quantum computers. In this paper we\n",
      "propose a simple visual technique (we call Q-Map) for quantum realisation of\n",
      "classical Boolean logic circuits. The proposed method utilises concepts from\n",
      "Boolean algebra to produce a quantum circuit with minimal number of quantum\n",
      "gates.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the latest research on quantum computing. \n",
      "Final Answer:  Quantum computing research is advancing rapidly, with recent developments focusing on areas like quantum internet computing, quantum game theory, and efficient implementation of Boolean functions using quantum circuits. For example, a recent paper \"Q-Map: Quantum Circuit Implementation of Boolean Functions\" proposes a novel method for visually translating classical Boolean logic circuits into quantum circuits using minimal quantum gates. \n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the latest research on quantum computing?', 'output': 'Quantum computing research is advancing rapidly, with recent developments focusing on areas like quantum internet computing, quantum game theory, and efficient implementation of Boolean functions using quantum circuits. For example, a recent paper \"Q-Map: Quantum Circuit Implementation of Boolean Functions\" proposes a novel method for visually translating classical Boolean logic circuits into quantum circuits using minimal quantum gates.'}\n"
     ]
    }
   ],
   "source": [
    "## Step9: Test the Agent with a query\n",
    "response = agent.invoke(\"What is the latest research on quantum computing?\")\n",
    "print(response) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a874bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to look up Aurangzeb on Wikipedia to get information about him and his contributions to the Mughal Empire. \n",
      "Action: wikipedia\n",
      "Action Input: Aurangzeb\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Aurangzeb\n",
      "Summary: Alamgir I (Muhi al-Din Muhammad; 3 November 1618 â€“ 3 March 1707), commonly known by the title Aurangzeb, was the sixth Mughal emperor, reigning from 1658 until his death in 1707. Under his reign, the Mughal Empire reached its greatest extent, with territory spanning nearly the entirety of the Indian subcontinent.\n",
      "Aurangzeb and the Mughals belonged to a branch of the Timurid dynasty.  He held administrative and military posts under his father Shah Jahan (r.â€‰1628â€“1658) and gained recognition as an accomplished military commander. Aurangzeb served as the viceroy of the Deccan in 1636â€“1637 and the governor of Gujarat in 1645â€“1647. He jointly administered the provinces of Multan and Sindh in 1648â€“1652 and continued expeditions into the neighboring Safavid territories. In September 1657, Shah Jahan nominated his eldest and liberalist son Dara Shikoh as his successor, a move repudiated by Aurangzeb, who proclaimed himself emperor in February 1658. In April 1658, Aurangzeb defeated the allied army of Shikoh and the Kingdom of Marwar at the Battle of Dharmat. Aurangzeb's decisive victory at the Battle of Samugarh in May 1658 cemented his sovereignty and his suzerainty was acknowledged throughout the Empire. After Shah Jahan recovered from illness in July 1658, Aurangzeb declared him incompetent to rule and imprisoned his father in the Agra Fort.\n",
      "Aurangzeb's reign is characterized by a period of rapid military expansion, with several dynasties and states being overthrown by the Mughals. The Mughals also surpassed Qing China as the world's largest economy and biggest manufacturing power. The Mughal military gradually improved and became one of the strongest armies in the world. A staunch Muslim, Aurangzeb is credited with the construction of numerous mosques and patronizing works of Arabic calligraphy. He successfully imposed the Fatawa-i Alamgiri as the principal regulating body of the empire and prohibited religiously forbidden activities in Islam. Although Aurangzeb suppressed several local revolts, he maintained cordial relations with foreign governments.\n",
      "His empire was also one of the largest in Indian history. However, his emperorship has a complicated legacy. His critics, citing his actions against the non-Muslims and his conservative view of Islam, argue that he abandoned the legacy of pluralism and tolerance of the earlier Mughal emperors. Others, however, reject these assertions, arguing that he opposed bigotry against Hindus, Sikhs and Shia Muslims and that he employed significantly more Hindus in his imperial bureaucracy than his predecessors.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know enough to answer the question. \n",
      "Final Answer: Aurangzeb was the sixth Mughal emperor, ruling from 1658 to 1707. He is known for expanding the Mughal Empire to its greatest territorial extent, overseeing significant military advancements, and promoting Islamic values through the construction of mosques and the implementation of Islamic law. However, his reign is also marked by controversy due to his policies towards non-Muslims, which some view as discriminatory and a departure from the earlier Mughal tolerance. \n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the latest research on quantum computing?', 'output': 'Quantum computing research is advancing rapidly, with recent developments focusing on areas like quantum internet computing, quantum game theory, and efficient implementation of Boolean functions using quantum circuits. For example, a recent paper \"Q-Map: Quantum Circuit Implementation of Boolean Functions\" proposes a novel method for visually translating classical Boolean logic circuits into quantum circuits using minimal quantum gates.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Step10: Test the Agent with a query\n",
    "agent.invoke(\"Who is aurangzeb? What is his contribution to the Mughal Empire?\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43249c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for information about \"langsmith\". \n",
      "Action: rag_tool\n",
      "Action Input: langsmith\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[Document(metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith'}, page_content='LangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic â€” score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.')]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have found the definition of LangSmith.\n",
      "Final Answer: LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Features include observability (analyzing traces and configuring metrics, dashboards, and alerts), evaluation (scoring application performance and getting human feedback on your data), and prompt engineering (iterating on prompts with version control and collaboration features). \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the latest research on quantum computing?', 'output': 'Quantum computing research is advancing rapidly, with recent developments focusing on areas like quantum internet computing, quantum game theory, and efficient implementation of Boolean functions using quantum circuits. For example, a recent paper \"Q-Map: Quantum Circuit Implementation of Boolean Functions\" proposes a novel method for visually translating classical Boolean logic circuits into quantum circuits using minimal quantum gates.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Step11: Test the Agent with a query\n",
    "agent.invoke(\"What is langsmith and what is the use of it?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9dcd5",
   "metadata": {},
   "source": [
    "## Using Prompt Hub with Agent\n",
    "Hub is a pre-defined list of prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86724671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7280fd883920>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7280fd883920>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7280cbebfd90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7280c1a1a590>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=512), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'rag_tool', 'description': 'Search any information about langsmith.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Another way to create the agent\n",
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "# Ensure you have the correct prompt for the agent\n",
    "\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm_groq,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1a9a523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7280fd883920>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7280fd883920>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7280cbebfd90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7280c1a1a590>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=512), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'rag_tool', 'description': 'Search any information about langsmith.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='rag_tool', description='Search any information about langsmith.', func=<bound method BaseRetriever.invoke of VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7280cbe4a610>, search_kwargs={'k': 1})>)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")   \n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ffc4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'quantum computing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2022-08-01\n",
      "Title: The Rise of Quantum Internet Computing\n",
      "Authors: Seng W. Loke\n",
      "Summary: This article highlights quantum Internet computing as referring to\n",
      "distributed quantum computing over the quantum Internet, analogous to\n",
      "(classical) Internet computing involving (classical) distributed computing over\n",
      "the (classical) Internet. Relevant to quantum Internet computing would be areas\n",
      "of study such as quantum protocols for distributed nodes using quantum\n",
      "information for computations, quantum cloud computing, delegated verifiable\n",
      "blind or private computing, non-local gates, and distributed quantum\n",
      "applications, over Internet-scale distances.\u001b[0m\u001b[32;1m\u001b[1;3mQuantum Internet computing is a rapidly developing field with many potential applications. It involves distributed quantum computing over the quantum Internet, analogous to classical internet computing.  \n",
      "\n",
      "Some key areas of study in quantum internet computing include:\n",
      "\n",
      "* Quantum protocols for distributed nodes using quantum information for computations\n",
      "* Quantum cloud computing\n",
      "* Delegated verifiable blind or private computing\n",
      "* Non-local gates\n",
      "* Distributed quantum applications over Internet-scale distances. \n",
      "\n",
      "\n",
      "A recent article \"The Rise of Quantum Internet Computing\" by Seng W. Loke published in 2022 highlights this exciting field.  \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the latest research on quantum computing?', 'output': 'Quantum Internet computing is a rapidly developing field with many potential applications. It involves distributed quantum computing over the quantum Internet, analogous to classical internet computing.  \\n\\nSome key areas of study in quantum internet computing include:\\n\\n* Quantum protocols for distributed nodes using quantum information for computations\\n* Quantum cloud computing\\n* Delegated verifiable blind or private computing\\n* Non-local gates\\n* Distributed quantum applications over Internet-scale distances. \\n\\n\\nA recent article \"The Rise of Quantum Internet Computing\" by Seng W. Loke published in 2022 highlights this exciting field.  \\n'}\n"
     ]
    }
   ],
   "source": [
    "## Execute the agent with a query\n",
    "response = agent_executor.invoke({\"input\": \"What is the latest research on quantum computing?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41362f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning. \n",
      "From a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mMachine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.  \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is machine learning?', 'output': 'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.  \\n'}\n"
     ]
    }
   ],
   "source": [
    "## Execute the agent with a query\n",
    "response = agent_executor.invoke({\"input\": \"What is machine learning?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
