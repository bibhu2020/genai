{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31f248f",
   "metadata": {},
   "source": [
    "## Runnable\n",
    "In LangChain, many components are designed to be Runnable, meaning you can call them with .invoke(), chain them with |, or deploy them via APIs. **A component in the Chain must be a runnable** .\n",
    "\n",
    "Here is the Runnable list: \n",
    "\n",
    "- PromptTemplate - Renders a prompt using input variables\n",
    "\n",
    "- LLM - Calls the language model with the prompt\n",
    "\n",
    "- OutputParser - Parses raw model output (e.g., to list, dict, or clean string)\n",
    "\n",
    "- Retriever - Retrieves relevant documents from a vector store\n",
    "\n",
    "- RunnableLambda - Wraps a Python function (like lambda x: x.upper())\n",
    "\n",
    "- RunnableParallel - Runs multiple Runnables in parallel and returns results\n",
    "\n",
    "- RunnablePassthrough - Just returns the input (like identity function)\n",
    "\n",
    "- RunnableBranch - Routes input to one of multiple branches based on logic \n",
    "\n",
    "- RunnableWithFallbacks - \tRuns a primary Runnable, falls back to backups if it fails\n",
    "\n",
    "- create_retrieval_chain() - Chains a retriever + LLM + prompt into one pipeline\n",
    "\n",
    "- create_stuff_documents_chain() - Converts docs + prompt into a final LLM query\n",
    "\n",
    "- Custom @Runnable - A decorator that can make your class and functions runnable. \n",
    "\n",
    "\n",
    "```python\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\"topic\": \"LangChain\"})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using RunnableLambda\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "uppercase = RunnableLambda(lambda x: x.upper())\n",
    "print(uppercase.invoke(\"hello\"))  # Output: \"HELLO\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e088bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Custom Runnable Class\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "class MyCustomRunnable(Runnable):\n",
    "    def invoke(self, input, config=None):\n",
    "        return input[::-1]  # reverses string\n",
    "\n",
    "MyCustomRunnable().invoke(\"langchain\")  # â†’ \"niahcnagnal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1dbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Custom Runnable by using decorator @runnable\n",
    "\n",
    "from langchain_core.runnables import runnable\n",
    "\n",
    "@runnable\n",
    "def shout_reverse(text: str) -> str:\n",
    "    return text[::-1].upper()\n",
    "\n",
    "print(shout_reverse.invoke(\"hello\"))  # Output: \"OLLEH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ad8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reversed': 'niahCgnaL', 'upper': 'LANGCHAIN', 'lower': 'langchain'}\n"
     ]
    }
   ],
   "source": [
    "## Using RunnableParallel\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "# Define individual runnables\n",
    "reverse = RunnableLambda(lambda x: x[::-1])\n",
    "uppercase = RunnableLambda(lambda x: x.upper())\n",
    "lowercase = RunnableLambda(lambda x: x.lower())\n",
    "\n",
    "# Combine using RunnableParallel\n",
    "parallel = RunnableParallel({\n",
    "    \"reversed\": reverse,\n",
    "    \"upper\": uppercase,\n",
    "    \"lower\": lowercase\n",
    "})\n",
    "\n",
    "# Invoke with a single input\n",
    "result = parallel.invoke(\"LangChain\")\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "589ec4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallback response\n"
     ]
    }
   ],
   "source": [
    "## using RunnableWithFallbacks\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
    "\n",
    "# Primary: will raise an error\n",
    "primary1 = RunnableLambda(lambda x: 1 / 0)  # Will fail\n",
    "\n",
    "# Fallback: returns a default string\n",
    "fallback = RunnableLambda(lambda x: \"Fallback response\")\n",
    "\n",
    "\n",
    "# Combine them\n",
    "resilient_runnable = RunnableWithFallbacks(\n",
    "    runnable=primary,\n",
    "    fallbacks=[fallback]\n",
    ")\n",
    "\n",
    "print(resilient_runnable.invoke(\"Test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Explain {concept} in simple terms.\")\n",
    "# llm = Ollama(model=\"gemma:2b\", temperature=0.1)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm= ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"gpt-4o\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Custom step: count words in the output\n",
    "count_words = RunnableLambda(lambda x: f\"Word count: {len(x.split())}\")\n",
    "\n",
    "chain = prompt | llm | parser | count_words\n",
    "\n",
    "result = chain.invoke({\"concept\": \"machine learning\"})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
