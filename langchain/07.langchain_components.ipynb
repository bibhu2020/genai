{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7974a333",
   "metadata": {},
   "source": [
    "## Learning LangChain Components\n",
    "- Prompt Templates\n",
    "- Models\n",
    "- Output Parser\n",
    "- Chain\n",
    "- Langsmith\n",
    "- LangServe\n",
    "\n",
    "https://python.langchain.com/docs/integrations/components/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150294e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (0.3.25)\n",
      "Requirement already satisfied: python-dotenv in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225920d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/miniconda3/envs/.langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM Model\n",
    "from utility.llm_factory import LLMFactory\n",
    "llm = LLMFactory.get_llm('openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fdacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"GenAI, short for Generative Artificial Intelligence, refers to a category of artificial intelligence systems designed to generate new content. It encompasses technologies and models capable of creating text, images, music, code, and other media. GenAI systems leverage complex algorithms, often based on neural networks, to analyze large datasets and learn patterns from which they can produce original content.\\n\\nOne of the most prominent examples of GenAI is the use of language models, like OpenAI's GPT (Generative Pre-trained Transformer), which can generate human-like text based on given prompts. Other forms of GenAI include systems that can create art, design products, compose music, and even develop video game levels. These models have a wide range of applications, including content creation, creative industries, and automating tasks traditionally performed by humans.\\n\\nThe impact of GenAI is significant, as it can enhance productivity, drive innovation, and provide personalized content. However, it also raises ethical concerns, particularly around issues like copyright, the potential for disinformation, and the replacement of human labor.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 12, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None} id='run--db094e11-24ee-41c5-a751-11a148c60530-0' usage_metadata={'input_tokens': 12, 'output_tokens': 210, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Creating a chatbot\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm= ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"gpt-4o\")\n",
    "# print(llm ) \n",
    "\n",
    "result = llm.invoke(\"What is GenAI?\")  # Example interaction with the chatbot\n",
    "print(result)  # Output the result of the interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0ba2f",
   "metadata": {},
   "source": [
    "#### Prompt Template (langchain core component) - langchain_core.prompts\n",
    "Prompt Template tells LLM how you want it to behave. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02e24b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are an export AI engineer. Answer the user's questions in detail.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an export AI engineer. Answer the user's questions in detail.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700917a4",
   "metadata": {},
   "source": [
    "#### Chain (langchain core component) - langhcinain_core.chains\n",
    "It helps to connect various components in langchain together so that that the message processed by one is sent to another in a sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5337df37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangSmith is a tool specifically designed for building, testing, and evaluating applications that utilize large language models. Here are some of its primary uses:\\n\\n1. **Debugging and Testing**: LangSmith allows developers to debug language model applications by providing them with the tools needed to inspect how the model generates outputs from inputs. This helps in understanding the model's behavior and identifying any issues or inconsistencies in how the application processes data.\\n\\n2. **Evaluation**: It offers features for evaluating language model applications at scale. Developers can use LangSmith to run tests and analyze the performance of their applications, ensuring that they meet desired accuracy and reliability standards.\\n\\n3. **Managing Dataflow**: LangSmith is particularly useful for managing the flow of data between various components of language model applications. It helps to streamline operations by simplifying integrations and enabling better coordination between different parts of the application.\\n\\n4. **Optimization**: Developers can use LangSmith to fine-tune and optimize their language model applications. By providing insights into specific areas where performance can be enhanced, it allows for the adjustment of parameters and modeling techniques to achieve more efficient outputs.\\n\\n5. **Collaboration and Versioning**: LangSmith supports collaboration among teams by allowing multiple developers to work on the same project concurrently. It often provides tools for version control, ensuring that changes are tracked and managed effectively.\\n\\nOverall, LangSmith is geared towards helping developers efficiently build robust and scalable applications that leverage the capabilities of large language models, simplifying many of the complexities associated with these powerful tools.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 305, 'prompt_tokens': 33, 'total_tokens': 338, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None} id='run--f039aab9-191e-45e1-97af-4d041d764238-0' usage_metadata={'input_tokens': 33, 'output_tokens': 305, 'total_tokens': 338, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm # prompt chaining with the llm\n",
    "result = chain.invoke({\"input\": \"What is LangSmith is used for?\"})  # Example interaction with the chatbot\n",
    "\n",
    "print(result)\n",
    "type(result)  # Output is a AIMessage object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8932a05b",
   "metadata": {},
   "source": [
    "#### Parser (core component)\n",
    "It decomposes the AIMessage objects, and get you the exact human readable response that you want. Let's see its use in Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cafcb7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a tool designed for developers and organizations working with language models. It focuses on improving the development, testing, and deployment of applications that integrate AI-driven language technologies. Here are some of the key uses and features of LangSmith:\n",
      "\n",
      "1. **Application Development**: LangSmith provides tools to make it easier to develop applications that incorporate language models. This includes offering APIs and SDKs that facilitate the integration of language models into various applications and services.\n",
      "\n",
      "2. **Model Evaluation and Fine-Tuning**: Users can employ LangSmith to evaluate the performance of different language models. It supports various metrics and benchmarks to assess models’ efficiency and effectiveness in meeting specific requirements. Additionally, LangSmith can aid in fine-tuning existing models to make them more aligned with a particular use case.\n",
      "\n",
      "3. **Experiment Management**: LangSmith offers frameworks for running and managing experiments with different models and configurations. This helps developers track changes, compare outcomes, and historically analyze previous experiments to better understand what configurations work best.\n",
      "\n",
      "4. **Collaboration and Sharing**: The platform often provides collaborative tools that allow team members to share model configurations, results, and documentation easily. This enhances collaborative efforts within an organization, making it easier for multiple teams or individuals to work together on language-based projects.\n",
      "\n",
      "5. **Deployment Optimization**: LangSmith can assist with optimizing the deployment of language models, ensuring that they run efficiently in production environments. This can include recommendations and tools for scaling, resource allocation, and performance monitoring.\n",
      "\n",
      "6. **Security and Compliance**: Depending on the platform's features, LangSmith may also include tools to ensure models are compliant with industry standards and regulations, offering features for auditing and maintaining data privacy and security.\n",
      "\n",
      "In summary, LangSmith provides a comprehensive suite of tools aimed at enhancing the development and management of language-based AI applications, offering capabilities that span from model development to deployment and collaboration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser  # Adding output parser to the chain\n",
    "\n",
    "result = chain.invoke({\"input\": \"What is LangSmith is used for?\"})  # Example interaction with the chatbot\n",
    "\n",
    "print(result)\n",
    "type(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
